---
title: "Modelling developmental changes in narrative similarity"
author: "Sarah K. Crockford"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

## Project Introduction

The following code analyses freely available (https://childes.talkbank.org) narrative production data from participants aged ~3 to 20 (N = 436). The data is taken from 5 corpora of English narratives, the English-Conti4 (N=99, ages 13, 14, 15), the English-ECSC [1] (N=188, ages 5 to 11), the English-MiamiMono (n=99, ages 7 & 9), the English-Slobin (N=60, ages 3, 4, 5, 9, 20) and the English-WolfHemp [2] (N=30, ages 6, 7, 8) (NB: The English-WolfHemp and English-Slobin, whilst initially included, was excluded, see notes below for why).   

This R Markdown file takes as its main inputs: 

1. The **raw data file** generated by the accompanying Matlab processing script (which is the csv containing the subject x full length narrative produced, as extracted from the Talkbank .cha/.xml files).

2. The **similarity files** generated by the accompanying Python script (sub x sub matrix of cosine similarity values). 

3. The **phenotypic/demographic file**. The phenotypic file was generated manually by myself to organize and process the data and is **not** available on the Talkbank website. Age data in the phenotypic file was extracted from the .cha/.xml files through the accompanying Matlab script.

The analyses presented in this R markdown document compares similarity in age (from youngest to oldest) to similarity in narrative production, as identified by two separate large language models (BERT, SGPT). More information about the language models is available in the accompanying Python script. 

To measure age similarity, we adopted similarity models created by Finn et al., (2020, see citations below). These are: 

1. nearest-neighbour similarity (the more similar I am in age with a person, the more similar I might be in my narrative production) 

2. convergence (as we become older, we might become more similar in narrative production) 

3. divergence (as we become older, we might become more dissimilar in narrative production). 

We also introduce a **fourth similarity** model (termed 'punctuacted similarity' in this analyses), developed to identify similarity at the tail ends of extremes (although we do not hypothesize this will explain narrative similarity). 

Briefly, this model tests the hypothesis that the younger and the older the population is the more similar they are, whilst those in the 'middle' are most dissimilar.

The age similarity functions in this script are written to be as reproducible as possible - that is you could re-use them to compute similarity within a different behavioral variable (i.e, height, intelligence etc.). You can also set the center value to the punctuated similarity model to whichever value you think it's important for your data to be centered around. 

Here is a breakdown of this document:

**Step 1**: set up all of the necessary custom functions to run the below analysis. 

**Step 2**: load in relevant libraries, read in your data, and hard code any necessary experimental info (for reproducibility purposes, these are the ONLY chunks that should require editing). One of the libraries ('similaritymodels') has been developed as past of this project, usage information and how to install it can be found here: https://github.com/sarahkaarina/similaritymodels

**Step 3**: extract age data from string variables, arrange your pheno file by ascending age, and plot age distribution. 

**Step 4**: create your sub x sub age similarity matrix and re-order you LM similarity matrices by ascending age.

**Step 5**: run a mantel test (correlation on the lower triangles of your similarity matrices w/ permuted p-value to check the re-ordering of rows and columns is not significant to the resulting correlation value, i.e. your correlation value is significant to the shape of your lower triangles). After running the mantel test, output clean data frame of results. NB: the function which computes mantel test, also corrects your p-values for the number of comparisons run on your data. More information on this test is found in the function script (see mantel_results_models). 

# Notes: 

[1] The English-ECSC corpus has been cut down for two reasons. Firstly, the adult data it includes (N = 26) are from children's respective caregivers **and** the age data in the files is stored simply as '18 years of age' (I am inclined to believe that parents in the study were not all aged 18). Given that the file ids for parents corresponds to the age of their child, it is not possible on my end to discern the parents age, other than to mark them as 'adult'. Therefore, for the time being I have excluded them from the final analysis. Secondly, children in this corpora came for repeat sessions, with the first session marked as 'Y1'. For comparison purposes (that all children in this similarity analysis were not repeats of the same individual), we only keep the data from the children's first session (i.e only files marked as 'Y1').

[2] Visual inspection of the narrative data revealed that for the English-WolfHemp corpus, transcriptions contained interactions between the experimenter and children not just the child's story. Therefore we excluded this corpus in our final analysis.

[3] Visual inspection of the narrative data for the English-Slobin corpus also revealed that narratives recorded for 3 and 4 year olds were exceedingly developmentally mature. This leads us to believe there may be some labeling issue with the transcripts. Therefore we removed this corpus as well (N=60).

For any queries, questions and/or mistakes, you can can contact the lead author of this study on the following emails (or push issues to the relevant git-hub page.).

We especially invite any researchers with comments/concerns regarding the excluded data to use our scripts to replicate our findings, whilst also including the missing corpora.

```{css style settings, echo=FALSE}
.link-style1 a {
  color: blue;
  text-decoration: underline;
}

.link-style2 a {
 color: blue;
}

Current institutional: .link-style1[[sarah.crockford@iit.it](mailto:sarah.crockford@iit.it)]

Personal: 
.link-style1[[sarah.crockford@iit.it](mailto:sarah.crockford@iit.it)]

```

```{r setup, include=FALSE}
rm(list=ls())
```

## Set up functions 

```{r custom functions}

# Function to extract a symmetric submatrix
extract_symmetric_submatrix <- function(matrix, ids) {

  indices <- which(rownames(matrix) %in% ids)
  submatrix <- matrix[indices, indices]
  
  return(submatrix)
}

# compute similarity on single value output

compute_similarity <- function(data, 
                               subids,
                               name2use,
                               resultpath,
                               save_out){
  
  matrix_similarity = data.frame()
  
  for (i in 1:nrow(data)){
    for (j in 1:nrow(data)){
      
      data_i = as.numeric(data[i,])
      data_j = as.numeric(data[j,])
      
      corr_similarity = cor(data_i, data_j, method = 'pearson')
      
      matrix_similarity[i, j] = corr_similarity
      
    }}
      
  rownames(matrix_similarity) = subids
  colnames(matrix_similarity) = subids
  
  saveoutfilename <- paste0(name2use, ".csv")
  saveoutfilepath <- file.path(resultpath, 
                               'final_similarity_matrices', 
                                saveoutfilename)
  
  if (save_out == TRUE){
    write.csv(matrix_similarity, saveoutfilepath, row.names=FALSE)}
  
  return(as.matrix(matrix_similarity))
}


# rank similarity dataframes

arrange_similarity_matrices <- function(sim2loopthrough, 
                                        ordered_subids_list,
                                        resultpath,
                                        plot){
  
  dfnames <- data.frame()

  for (df in 1:length(sim2loopthrough)){
    
    name2use <- names(sim2loopthrough[df])
    
    df2use <- data.frame(sim2loopthrough[[df]])
    df2use$subids <- as.character(rownames(df2use))
    
    rank_name2use <- paste0("rank_", name2use)
    dfnames <- rbind(dfnames, rank_name2use)
    
    saveoutfilename <- paste0(rank_name2use, ".csv")
    saveoutfilepath <- file.path(resultpath, 
                                 'final_similarity_matrices', 
                                 saveoutfilename)

    #rank df by ordered subid_list
    ranked_df <- rank_subxsub_mat(df2use, 
                                  ordered_subids_list,
                                  "subids", 
                                  TRUE)
    assign(rank_name2use, ranked_df)
    
    if (plot == TRUE){
      write.csv(ranked_df, saveoutfilepath, row.names=FALSE)}
  
  } # end for loop
    
  rankdf2loopthrough <- do.call("list", mget(dfnames[[1]]))

  return(rankdf2loopthrough)

} # end function arrange_similarity_matrices

# compute mantel results

mantel_results_models <- function(x, y, nperm, n_models){
  
  # function takes two separate lists of dataframes as arguments
  # where x = list of data frames that model behvaioral similarity (4 models)
  # and y = list of data frames that model dependent variable similarity
  # nperm is the n of permutations you want to run (i.e. 1000)
  # n_models is the number of behavioral models you are using FIX ME
  
  # using package vegan for the mantel() function, with spearman method*
  # *because distribution of similarity is not parametric 
  # cit. https://jkzorz.github.io/2019/07/08/mantel-test.html
  
  # NB: switched to the vegan package, because the metan one was defaulting into spearman and there was no way to edit that (we need a non-parametric test)
  
  n_comparisons = length(y)

  len_final_df = n_models*n_comparisons

  model_res_r <- data.frame()
  model_res_p <- data.frame()
  rownames_df <- data.frame()

  modelname = names(x)
  comparisonname = names(y)

  for (i in 1:length(x)){
    for (j in 1:length(y)){

        result_name <- paste0(modelname[i], comparisonname[j])

        model2use = x[[i]]
        data2use = y[[j]]

        model_out = mantel(model2use,
                           data2use,
                           method = "spearman",
                           permutations = nperm,
                           na.rm = TRUE)

        model_res_r <- rbind(model_res_r, model_out$statistic) # r-value
        model_res_p <- rbind(model_res_p, model_out$signif) # p-value

        rownames_df <- rbind(rownames_df, result_name)
    }}

  colnames(model_res_r) <- "r"
  colnames(model_res_p) <- "p_value"

  model_res <- cbind(model_res_p, model_res_r)
  rownames(model_res) <- rownames_df[[1]]

  model_res$p_value_adjusted <- p.adjust(model_res$p_value, method = "fdr")

  return(model_res)

} # end function mantel_results_models


make_similarity_matrices <- function(behave_vec,
                                     index,
                                     center_value_list,
                                     resultpath,
                                     save_out){

  dataframes2loopthrough <- list()

  behave_nn <- nearest_neighbours(behave_vec) # absolute difference
  nn_name <- "behave_nn"
  behave_conv <- convergence(behave_vec) # minimum pair
  conv_name <- "behave_conv"
  behave_div <- divergence(behave_vec) # max(sample) - minimum pair
  div_name <- "behave_div"

  df_names_finn <- c(nn_name, conv_name, div_name)

  df_names_behave <- c()
  for (i in 1:length(center_value_list)){
    behave_bow <- bow_tie(behave_vec, center_value_list[i]) # see function

    df_name <- paste0('center_value_', i)
    df_names_behave[i] <- df_name

    assign(df_name, behave_bow)
  }

  df_names <- c(df_names_finn, df_names_behave)

  dataframes2loopthrough <- do.call("list", mget(df_names))

  for (df in 1:length(dataframes2loopthrough)){

    df2use <- dataframes2loopthrough[[df]]

    dfname <- names(dataframes2loopthrough)

    final_df <- scale_matrix(df2use)

    # replace diagonal values with 1
    diag(final_df) <- round(1, digits = 0)
    rownames(final_df) <- index

    assign(dfname[df], final_df)

    saveoutfilepath <- file.path(resultpath,
                                 paste0(dfname[df], ".csv"))

    if(save_out == TRUE){
      write.csv(final_df, saveoutfilepath, row.names=FALSE)}

  }

  final_dataframes2loopthrough <- do.call("list", mget(df_names))
  
  return(final_dataframes2loopthrough)

} # end function run behave model similarity

compare_correlations <- function(r1_value,
                                 r2_value,
                                 alpha_level,
                                 n_1,
                                 n_2){
  
  # NB: applies to BOTH Pearson or Spearman's
  
  # REFs
  # https://blogs.sas.com/content/iml/2017/09/20/fishers-transformation-correlation.html
  # https://www.medcalc.org/manual/comparison-of-correlation-coefficients.php
  # Fisher (1925): http://krishikosh.egranth.ac.in/bitstream/1/2048218/1/0039_2689A.pdf
  # p_value from z score: https://www.r-bloggers.com/2022/05/calculate-the-p-value-from-z-score-in-r/
  
  # as a test case I used the exact values in the Medcalc link
  # and I got the same results 
  
  result_names <- c("r_values",
                    "z_scores",
                    "standard_error",
                    "Fisher's z",
                    "p_value",
                    "significance")
  result <- vector("list", length(result_names))
  names(result) <- result_names
  
  # save the original r values
  result[["r_values"]] <- c("r1" = r1_value, "r2" = r2_value)
  
  # calculate z scores for the two pearson r coefficients
  z1_value <- (1/2)*log((1+r1_value)/(1-r1_value)) 
  z2_value <- (1/2)*log((1+r2_value)/(1-r2_value)) 
  result[["z_scores"]] <- c("z1" = z1_value, "z2" = z2_value)
  
  # calculate the standard error based on sample size
  se_value1 <- (1/(n_1 - 3))
  se_value2 <- (1/(n_2 - 3))
  
  standard_error <- sqrt(se_value1 + se_value2)
  result[["standard_error"]] <- standard_error
  
  # compute Fisher's z
  # NB: we need to take the absolute value because this 
  # eliminates the effect of which correlation is 
  # first and which is second
  
  z <- abs((z1_value - z2_value)/standard_error)
  result[["Fisher's z"]] <- z
  
  # test significance of Fisher's z (rounded to 4 decimal places)
  # need to see the lower.tail to FALSE as we are only 
  # evaluating positive z scores 
  p_value <- pnorm(z, lower.tail = FALSE)
  p_value_formatted <- format(round(p_value, 4), nsmall = 4)
  
  significant <- ifelse(p_value > alpha_level, "No", "Yes")
  
  result[["p_value"]] <- p_value_formatted 
  result[["significance"]] <- significant
  
  return(result)
}

run_mantel_analysis <- function(discovery_dataframes2loopthrough,
                                replication_dataframes2loopthrough,
                                discovery_ranked_sim2loopthrough,
                                replication_ranked_sim2loopthrough,
                                model,
                                llm_model,
                                plot_title,
                                nperm){
  # model = "behave_nn"
  # llm_model = "GPT"
  # plot_title = "Nearest Neighbours"
  
  
  result_names <- c("plot",
                    "model",
                    "result_df")
  mantel_analysis_results <- vector("list", length(result_names))
  names(mantel_analysis_results) <- result_names
  
  #mantel_analysis_results <- c()
  
    discovery_model_res <- 
      mantel_results_models(discovery_dataframes2loopthrough[model], 
                                      discovery_ranked_sim2loopthrough,
                                        nperm,
                                        1)
    
    replication_model_res <-
      mantel_results_models(replication_dataframes2loopthrough[model],
                            replication_ranked_sim2loopthrough,
                                        nperm,
                                        1)
    
    discovery_model_res$survived <-
      ifelse(discovery_model_res$p_value_adjusted < alpha, "Y", "N")
    replication_model_res$survived <-
      ifelse(replication_model_res$p_value_adjusted < alpha, "Y", "N")
    
    plot_df <- data.frame(discovery_r = discovery_model_res$r,
                          discovery_survived =
                            discovery_model_res$survived,
                          replication_r = replication_model_res$r,
                          replication_survived =
                            replication_model_res$survived)
    
    plot_df$survived <- ifelse(plot_df$discovery_survived == "Y" & 
                                 plot_df$replication_survived == "Y", "Y",
                               "N")
    
    plot_df$comparison <- rownames(discovery_model_res)
    
    x_title <- paste0(llm_model, " RSA R results for replication")
    y_title <- paste0(llm_model, " RSA R results for discovery")
    
    plot <- ggplot(plot_df, aes(x = replication_r, y = discovery_r)) +
                  geom_point(aes(colour=survived))+
                  geom_smooth(method = "lm") +
                  scale_color_manual(name="Group", 
                                     values=c("Y"="red", 
                                              "N"="black"),
                                     labels=c("Y" = "Survived comparison", 
                                              "N" = "Did not survive comparison")) +    
                                     labs(title = plot_title,
                                            x = x_title,
                                            y = y_title) + mytheme 
    
    mantel_analysis_results[["plot"]] <- plot
    
    behave_relationship <- lm(discovery_model_res$r ~ replication_model_res$r)
    
    mantel_analysis_results[["model"]] <- behave_relationship
    mantel_analysis_results[["result_df"]] <- plot_df
  
    return(mantel_analysis_results)
}

```

## Set up enviornment 

```{r load libraries, message = FALSE, warning = FALSE}
library(easypackages)

# HOW TO INSTALL SVA
# https://bioconductor.org/packages/release/bioc/html/sva.html

libraries("here",
          "ggplot2",
          "tidyverse", 
          "psych", 
          "reticulate",
          "graph4lg", 
          "ade4", 
          "vegan",
          "similaritymodels",
          "caret",
          "tidyverse",
          "robustbase",
          "egg",
          "reshape2",
          "lme4",
          "lmerTest",
          "cocor",
          "sva",
          "multcomp",
          "lmtest",
          "knitr",
          "kableExtra")

codepath = here("code")
resultpath = here("results")
datapath = here("data")
plotpath = here("plots")

# make plots pretty

#https://stackoverflow.com/questions/6736378/how-do-i-change-the-background-color-of-a-plot-made-with-ggplot2
mytheme <- list(
  theme_classic()+
    theme(panel.background = element_blank(),strip.background = element_rect(colour=NA, fill=NA),panel.border = element_rect(fill = NA, color = "black"),
          legend.title = element_blank(),legend.position="bottom", strip.text = element_text(face="bold", size=9),
          axis.text=element_text(face="bold"),axis.title = element_text(face="bold"),plot.title = element_text(face = "bold", hjust = 0.5,size=13))
)
```

# Get filenames to read in 

This loop will ensure every one of those files is read into this markdown (If you don't want that to happen, I recommend editing this portion of the script to read in the single file you want)

```{r load in files, message = FALSE, warning = FALSE}

# read pheno data file
phenofilename <- file.path(datapath, "pheno", "corrected_pheno_file.csv")
final_data_corrected <- read.csv(phenofilename, header = TRUE)

# read similarity matrices 
simpath <- file.path(resultpath, "final_similarity_matrices")
filenames <- list.files(path=simpath, pattern="+.*csv")

for(i in filenames){
  
    datafilepath <- file.path(simpath, i)
    name2use <- sub(".csv", "", i)
    
    assign(name2use, 
           read.csv(datafilepath, 
                    header = TRUE, 
                    na.strings = "NaN", 
                    sep = ",",
                    row.names = 1))
}

name2use <- sub(".csv", "", filenames)

# update column names so that they match rownames
colnames(sim_df_BERT_cosine) <- rownames(sim_df_BERT_cosine)
colnames(sim_df_SGPT_cosine) <- rownames(sim_df_SGPT_cosine)

# get list of similarity matrices to loop through
sim2loopthrough <- do.call("list", mget(name2use))

# age of onset of puberty (childhood v. adolescence)
pubertal_age = 10

center_ages <- c(pubertal_age)

#set seed
set.seed(999)

#set permutation runs for mantel test
nperm = 10000

# set p-value threshold
alpha = 0.05

# n of age similarity models we will build
n_behave_models = 4

# number of subjects in our study
nsubs = nrow(final_data_corrected)

```

## Store column name information

```{r gpt column name information}

column_function <- c("function_entropy_gpt_layer_0",
                      "function_entropy_gpt_layer_1",
                      "function_entropy_gpt_layer_2",
                      "function_entropy_gpt_layer_3",
                      "function_entropy_gpt_layer_4",
                      "function_entropy_gpt_layer_5",
                      "function_entropy_gpt_layer_6",
                      "function_entropy_gpt_layer_7",
                      "function_entropy_gpt_layer_8",
                      "function_entropy_gpt_layer_9",
                      "function_entropy_gpt_layer_10",
                      "function_entropy_gpt_layer_11",
                      "function_entropy_gpt_layer_12")


column_content <- c("content_entropy_gpt_layer_0",
                      "content_entropy_gpt_layer_1",
                      "content_entropy_gpt_layer_2",
                      "content_entropy_gpt_layer_3",
                      "content_entropy_gpt_layer_4",
                      "content_entropy_gpt_layer_5",
                      "content_entropy_gpt_layer_6",
                      "content_entropy_gpt_layer_7",
                      "content_entropy_gpt_layer_8",
                      "content_entropy_gpt_layer_9",
                      "content_entropy_gpt_layer_10",
                      "content_entropy_gpt_layer_11",
                      "content_entropy_gpt_layer_12")

column_predicate <- c("predicate_entropy_gpt_layer_0",
                      "predicate_entropy_gpt_layer_1",
                      "predicate_entropy_gpt_layer_2",
                      "predicate_entropy_gpt_layer_3",
                      "predicate_entropy_gpt_layer_4",
                      "predicate_entropy_gpt_layer_5",
                      "predicate_entropy_gpt_layer_6",
                      "predicate_entropy_gpt_layer_7",
                      "predicate_entropy_gpt_layer_8",
                      "predicate_entropy_gpt_layer_9",
                      "predicate_entropy_gpt_layer_10",
                      "predicate_entropy_gpt_layer_11",
                      "predicate_entropy_gpt_layer_12")

```

```{r column name information}

bertcolumn_function <- c("function_entropy_bert_layer_0",
                      "function_entropy_bert_layer_1",
                      "function_entropy_bert_layer_2",
                      "function_entropy_bert_layer_3",
                      "function_entropy_bert_layer_4",
                      "function_entropy_bert_layer_5",
                      "function_entropy_bert_layer_6",
                      "function_entropy_bert_layer_7",
                      "function_entropy_bert_layer_8",
                      "function_entropy_bert_layer_9",
                      "function_entropy_bert_layer_10",
                      "function_entropy_bert_layer_11",
                      "function_entropy_bert_layer_12")


bertcolumn_content <- c("content_entropy_bert_layer_0",
                      "content_entropy_bert_layer_1",
                      "content_entropy_bert_layer_2",
                      "content_entropy_bert_layer_3",
                      "content_entropy_bert_layer_4",
                      "content_entropy_bert_layer_5",
                      "content_entropy_bert_layer_6",
                      "content_entropy_bert_layer_7",
                      "content_entropy_bert_layer_8",
                      "content_entropy_bert_layer_9",
                      "content_entropy_bert_layer_10",
                      "content_entropy_bert_layer_11",
                      "content_entropy_bert_layer_12")

bertcolumn_predicate <- c("predicate_entropy_bert_layer_0",
                      "predicate_entropy_bert_layer_1",
                      "predicate_entropy_bert_layer_2",
                      "predicate_entropy_bert_layer_3",
                      "predicate_entropy_bert_layer_4",
                      "predicate_entropy_bert_layer_5",
                      "predicate_entropy_bert_layer_6",
                      "predicate_entropy_bert_layer_7",
                      "predicate_entropy_bert_layer_8",
                      "predicate_entropy_bert_layer_9",
                      "predicate_entropy_bert_layer_10",
                      "predicate_entropy_bert_layer_11",
                      "predicate_entropy_bert_layer_12")

```

# Rank phenotypic files 

```{r}

rownames(final_data_corrected) <- 1:nsubs 

dataset_names <- unique(final_data_corrected$dataset)

replist <- c()
disclist <- c()

for (i in 1:length(dataset_names)){
  
  subbed_dataset <- subset(final_data_corrected, 
                           dataset == dataset_names[i])
  sample_index <- sample(rownames(subbed_dataset))
  sample_index <- as.numeric(sample_index)
  
  length_index <- length(sample_index)
  half_index <- ceiling(length_index/2)
  
  if (length(sample_index) %% 2 == 0){
    rep <- sample_index[1:half_index]
    disc <- sample_index[(half_index+1):length_index]
    }else if (i == 2 | i == 5){
      rep <- sample_index[1:half_index] 
      disc <- sample_index[(half_index + 1):length_index]
    }else if (i == 9 | i == 10){
      rep <- sample_index[1:(half_index-1)] 
      disc <- sample_index[((half_index-1) + 1):length_index]  
    }

  replist[[i]] <- rep
  disclist[[i]] <- disc
  
}

# Split the indices into two subsets
replication_index <- sort(unlist(replist, recursive = TRUE))
discovery_index <- sort(unlist(disclist, recursive = TRUE))

# Create the two subsets
replication_pheno <- final_data_corrected[replication_index, ]
discovery_pheno <- final_data_corrected[discovery_index, ]

# Rank phenotypic data files by increasing age

replication_rank_byage <-
  replication_pheno[order(replication_pheno$final_age),]
discovery_rank_byage <-
  discovery_pheno[order(discovery_pheno$final_age),]

replication_age <- replication_rank_byage$final_age
replication_subids <- replication_rank_byage$id

discovery_age <- discovery_rank_byage$final_age
discovery_subids <- discovery_rank_byage$id

```

# Split narrative similarity dataframes

```{r}
discovery_narrative <- list()
replication_narrative <- list()

for (i in 1:length(sim2loopthrough)){
  
  dataframe <- sim2loopthrough[[i]]
  
  # Extract the two symmetric submatrices
  discovery_narrative[[i]] <- extract_symmetric_submatrix(dataframe,
                                                      discovery_subids)
  replication_narrative[[i]] <- extract_symmetric_submatrix(dataframe,
                                                    replication_subids)

}

names(discovery_narrative) <- names(sim2loopthrough)
names(replication_narrative) <- names(sim2loopthrough)

```

# Check discovery and replication distributions

```{r, replication plots}

plot_age <- ggplot(replication_rank_byage, 
                   aes(x = final_age)) + 
                      geom_density() + mytheme + labs(x="Age")

print(plot_age) 

plot_count <- ggplot(replication_rank_byage, 
                   aes(x = word_count)) + 
                   geom_density() + mytheme + labs(x="Word Count")

print(plot_count) 

```


```{r, discovery plots}

plot_age <- ggplot(discovery_rank_byage, 
                   aes(x = final_age)) + 
                geom_density() + mytheme + labs(x="Age")

print(plot_age) 

plot_count <- ggplot(discovery_rank_byage, 
                   aes(x = word_count)) + 
                geom_density() + mytheme + labs(x="Word Count")

print(plot_count) 

```

## Build similarity matrices across layers for discovery data

```{r}

resultpath_discovery <- file.path(resultpath, "discovery")

data_content <- discovery_rank_byage %>% dplyr::select(all_of(c(column_content)))
data_predicate <- discovery_rank_byage %>% dplyr::select(all_of(c(column_predicate)))
data_function <- discovery_rank_byage %>% dplyr::select(all_of(c(column_function)))

gpt_discovery_sim2loopthrough <- list()

subids <- discovery_rank_byage$id

gpt_discovery_sim2loopthrough[["content"]] <- compute_similarity(data_content,
                                                                subids,
                                                                'gpt_content_disc_similarity',
                                                                resultpath_discovery,
                                                                TRUE)

gpt_discovery_sim2loopthrough[["predicate"]] <- compute_similarity(data_predicate,
                                                                subids,
                                                                'gpt_predicate_disc_similarity',
                                                                resultpath_discovery,
                                                                TRUE)

gpt_discovery_sim2loopthrough[["function"]] <- compute_similarity(data_function,
                                                                subids,
                                                                'gpt_function_disc_similarity',
                                                                resultpath_discovery,
                                                                TRUE)


```

## Build similarity matrices across layers for replication data

```{r}

resultpath_replication <- file.path(resultpath, "replication")

data_content <- replication_rank_byage %>% dplyr::select(all_of(c(column_content)))
data_predicate <- replication_rank_byage %>% dplyr::select(all_of(c(column_predicate)))
data_function <- replication_rank_byage %>% dplyr::select(all_of(c(column_function)))

gpt_replication_sim2loopthrough <- list()

subids <- replication_rank_byage$id

gpt_replication_sim2loopthrough[["content"]] <- compute_similarity(data_content,
                                                                subids,
                                                                'gpt_content_rep_similarity',
                                                                resultpath_replication,
                                                                TRUE)

gpt_replication_sim2loopthrough[["predicate"]] <- compute_similarity(data_predicate,
                                                                subids,
                                                                'gpt_predicate_rep_similarity',
                                                                resultpath_replication,
                                                                TRUE)

gpt_replication_sim2loopthrough[["function"]] <- compute_similarity(data_function,
                                                                subids,
                                                                'gpt_function_rep_similarity',
                                                                resultpath_replication,
                                                                TRUE)


```

### BERT

```{r}

resultpath_discovery <- file.path(resultpath, "discovery")

data_content <- discovery_rank_byage %>% dplyr::select(all_of(c(bertcolumn_content)))
data_predicate <- discovery_rank_byage %>% dplyr::select(all_of(c(bertcolumn_predicate)))
data_function <- discovery_rank_byage %>% dplyr::select(all_of(c(bertcolumn_function)))

bert_discovery_sim2loopthrough <- list()

subids <- discovery_rank_byage$id

bert_discovery_sim2loopthrough[["content"]] <- compute_similarity(data_content,
                                                                subids,
                                                                'bert_content_disc_similarity',
                                                                resultpath_discovery,
                                                                TRUE)

bert_discovery_sim2loopthrough[["predicate"]] <- compute_similarity(data_predicate,
                                                                subids,
                                                                'bert_predicate_disc_similarity',
                                                                resultpath_discovery,
                                                                TRUE)

bert_discovery_sim2loopthrough[["function"]] <- compute_similarity(data_function,
                                                                subids,
                                                                'bert_function_disc_similarity',
                                                                resultpath_discovery,
                                                                TRUE)

```

## Build similarity matrices across layers for replication data

```{r}

resultpath_replication <- file.path(resultpath, "replication")

data_content <- replication_rank_byage %>% dplyr::select(all_of(c(bertcolumn_content)))
data_predicate <- replication_rank_byage %>% dplyr::select(all_of(c(bertcolumn_predicate)))
data_function <- replication_rank_byage %>% dplyr::select(all_of(c(bertcolumn_function)))

bert_replication_sim2loopthrough <- list()

subids <- replication_rank_byage$id

bert_replication_sim2loopthrough[["content"]] <- compute_similarity(data_content,
                                                                subids,
                                                                'bert_content_rep_similarity',
                                                                resultpath_replication,
                                                                TRUE)

bert_replication_sim2loopthrough[["predicate"]] <- compute_similarity(data_predicate,
                                                                subids,
                                                                'bert_predicate_rep_similarity',
                                                                resultpath_replication,
                                                                TRUE)

bert_replication_sim2loopthrough[["function"]] <- compute_similarity(data_function,
                                                                subids,
                                                                'bert_function_rep_similarity',
                                                                resultpath_replication,
                                                                TRUE)

```

## Analysis plan:

1. Create similarity matrix ranked in order of age (from youngest to eldest):
          a. NEAREST NEIGHBOURS
          b. CONVERGENCE (min(i,j))
          c. DIVERGENCE (max(sample) - min(i,j))
          d. PUNCTUACTED (age of literacy/age of adolescence)

2. Vectorize and compare narrative data, resulting in a sub x sub matrix of language related values.

3. Compare the two similarity matrices: do we find that pair similarity in age is related to similarity in narratives and other language related metrics?

## Create age ranked similarity matrices

We are going to set plot to TRUE so that we save out our similarity matrices to plot them later using python.

```{r, message = FALSE, warning = FALSE}

saveoutfilepath <- file.path(resultpath_discovery, 'final_similarity_matrices')

ranked_discovery_sim2loopthrough <-
  arrange_similarity_matrices(discovery_narrative,
                              discovery_subids,
                              resultpath_discovery,
                              plot = TRUE)

discovery_dataframes2loopthrough <- make_similarity_matrices(discovery_age, 
                                                             discovery_subids,
                                                             center_ages,
                                                             saveoutfilepath,
                                                             save_out = TRUE)

```

```{r, message = FALSE, warning = FALSE}

saveoutfilepath <- file.path(resultpath_replication,
                             'final_similarity_matrices')

ranked_replication_sim2loopthrough <-
  arrange_similarity_matrices(replication_narrative, 
                              replication_subids, 
                              resultpath_replication, 
                              plot = TRUE)

replication_dataframes2loopthrough <- 
  make_similarity_matrices(replication_age, 
                           replication_subids,
                           center_ages,
                           saveoutfilepath,
                           save_out = TRUE)

```


## Compute similarity between age and language

Final code runs a mantel test to check if the lower triangle of the nn, convergence, divergence and punctuacted similarity sub x sub age models correlate with the lower triangle of the sub x sub narrative production data. 

Before running the final analysis, we check the relationship between each of the language model matrices to see how similar they are to each other.

The results return a Spearman's rank r, a raw p-value based on 10000 permutations of the lower triangle comparison and an FDR corrected (p-adjusted) p-value, corrected for all of the comparisons. 

NB: Choice of this statistic is for consistency with Finn et al., 2020 and Camacho et al., 2023 method of analysis.  

```{r,  message = FALSE, warning = FALSE}

gpt_discovery_ranked_sim2loopthrough <- c(ranked_discovery_sim2loopthrough[2], 
                                       gpt_discovery_sim2loopthrough)

gpt_replication_ranked_sim2loopthrough <- c(ranked_replication_sim2loopthrough[2], 
                                       gpt_replication_sim2loopthrough)
```

```{r,  message = FALSE, warning = FALSE}

bert_discovery_ranked_sim2loopthrough <- c(ranked_discovery_sim2loopthrough[1], 
                                     bert_discovery_sim2loopthrough)

bert_replication_ranked_sim2loopthrough <- c(ranked_replication_sim2loopthrough[1], 
                                       bert_replication_sim2loopthrough)

```

# Check relationship between age and language model similarity matrices 

# NEAREST NEIGHBORS

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

gpt_nn_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                      replication_dataframes2loopthrough,
                                      gpt_discovery_ranked_sim2loopthrough,
                                      gpt_replication_ranked_sim2loopthrough,
                                      "behave_nn",
                                      "GPT",
                                      "Nearest Neighbours",
                                       nperm)

print(summary(gpt_nn_results[["model"]]))
df_nn_gpt <- gpt_nn_results[["result_df"]]

df_nn_gpt %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_nn_gpt <- subset(df_nn_gpt, df_nn_gpt$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_nn_gpt)))

plot <- gpt_nn_results[["plot"]]
print(plot)

# write out dataframes and plots 

if (nrow(survived_comparisons_nn_gpt) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_nn_gpt.csv")
  write.csv(survived_comparisons_nn_gpt, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "nn_gpt_results.png")
ggsave(plot2save, plot)

```

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

bert_nn_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                      replication_dataframes2loopthrough,
                                      bert_discovery_ranked_sim2loopthrough,
                                      bert_replication_ranked_sim2loopthrough,
                                      "behave_nn",
                                      "BERT",
                                      "Nearest Neighbours",
                                       nperm)


print(summary(bert_nn_results[["model"]]))
df_nn_bert <- bert_nn_results[["result_df"]]

df_nn_bert %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_nn_bert <- subset(df_nn_bert, df_nn_bert$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_nn_bert)))

plot <- bert_nn_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_nn_bert) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_nn_bert.csv")
  write.csv(survived_comparisons_nn_bert, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "nn_bert_results.png")
ggsave(plot2save, plot)

```

# CONVERGENCE

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

gpt_conv_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                        replication_dataframes2loopthrough,
                                        gpt_discovery_ranked_sim2loopthrough,
                                        gpt_replication_ranked_sim2loopthrough,
                                        "behave_conv",
                                        "GPT",
                                        "Convergence",
                                         nperm)

print(summary(gpt_conv_results[["model"]]))
df_conv_gpt <- gpt_conv_results[["result_df"]]

df_conv_gpt %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_conv_gpt <- subset(df_conv_gpt, 
                                        df_conv_gpt$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_conv_gpt)))

plot <- gpt_conv_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_conv_gpt) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_conv_gpt.csv")
  write.csv(survived_comparisons_conv_gpt, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "conv_gpt_results.png")
ggsave(plot2save, plot)

```

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

bert_conv_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                        replication_dataframes2loopthrough,
                                        bert_discovery_ranked_sim2loopthrough,
                                        bert_replication_ranked_sim2loopthrough,
                                        "behave_conv",
                                        "BERT",
                                        "Convergence",
                                         nperm)

print(summary(bert_conv_results[["model"]]))
df_conv_bert <- bert_conv_results[["result_df"]]

df_conv_bert %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_conv_bert <- subset(df_conv_bert, 
                                         df_conv_bert$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_conv_bert)))


plot <- bert_conv_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_conv_bert) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_conv_bert.csv")
  write.csv(survived_comparisons_conv_bert, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "conv_bert_results.png")
ggsave(plot2save, plot)

```

# DIVERGENCE

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

gpt_div_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                       replication_dataframes2loopthrough,
                                       gpt_discovery_ranked_sim2loopthrough,
                                       gpt_replication_ranked_sim2loopthrough,
                                       "behave_div",
                                       "GPT",
                                       "Divergence",
                                        nperm)

print(summary(gpt_div_results[["model"]]))
df_div_gpt <- gpt_div_results[["result_df"]]

df_div_gpt %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_div_gpt <- subset(df_div_gpt, df_div_gpt$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_div_gpt)))

plot <- gpt_div_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_div_gpt) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_div_gpt.csv")
  write.csv(survived_comparisons_div_gpt, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "div_gpt_results.png")
ggsave(plot2save, plot)

```

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

bert_div_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                        replication_dataframes2loopthrough,
                                        bert_discovery_ranked_sim2loopthrough,
                                        bert_replication_ranked_sim2loopthrough,
                                        "behave_div",
                                        "BERT",
                                        "Divergence",
                                         nperm)

print(summary(bert_div_results[["model"]]))
df_div_bert <- bert_div_results[["result_df"]]

df_div_bert %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_div_bert <- subset(df_div_bert, 
                                        df_div_bert$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_div_bert)))

plot <- bert_div_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_div_bert) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_div_bert.csv")
  write.csv(survived_comparisons_div_bert, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "div_bert_results.png")
ggsave(plot2save, plot)

```

# CENTER VALUE 1

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

gpt_cv1_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                      replication_dataframes2loopthrough,
                                      gpt_discovery_ranked_sim2loopthrough,
                                      gpt_replication_ranked_sim2loopthrough,
                                      "center_value_1",
                                      "GPT",
                                      "Punctuacted Similarity, center age 10",
                                       nperm)

print(summary(gpt_cv1_results[["model"]]))
df_cv1_gpt <- gpt_cv1_results[["result_df"]]

df_cv1_gpt %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_cv1_gpt <- subset(df_cv1_gpt, df_cv1_gpt$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_cv1_gpt)))

plot <- gpt_cv1_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_cv1_gpt) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_cv1_gpt.csv")
  write.csv(survived_comparisons_cv1_gpt, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "cv1_gpt_results.png")
ggsave(plot2save, plot)

```

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

bert_cv1_results <- run_mantel_analysis(discovery_dataframes2loopthrough,
                                      replication_dataframes2loopthrough,
                                      bert_discovery_ranked_sim2loopthrough,
                                      bert_replication_ranked_sim2loopthrough,
                                      "center_value_1",
                                      "BERT",
                                      "Punctuacted Similarity, center age 10",
                                      nperm)


print(summary(bert_cv1_results[["model"]]))
df_cv1_bert <- bert_cv1_results[["result_df"]]

df_cv1_bert %>%
  knitr::kable(format = "html") %>%
  kable_styling()

survived_comparisons_cv1_bert <- subset(df_cv1_bert, 
                                        df_cv1_bert$survived == "Y")

print(paste0("Number of surviving comparisons: ",
      nrow(survived_comparisons_cv1_bert)))

plot <- bert_cv1_results[["plot"]]
print(plot)

# write out dataframes and plots
if (nrow(survived_comparisons_cv1_bert) > 0){
  file2save <- file.path(resultpath, "survived_comparisons_cv1_bert.csv")
  write.csv(survived_comparisons_cv1_bert, file2save)
}else{
  "No comparisons survived"
}

plot2save <- file.path(plotpath, "cv1_bert_results.png")
ggsave(plot2save, plot)

```

