"0",""
"0","# Function to compute divergence similarity"
"0","divergence <- function(behave_data){"
"0",""
"0","  divergence_df <- data.frame()"
"0",""
"0","  sample_max <- max(behave_data)"
"0",""
"0","  for (i in 1:length(behave_data)){"
"0","    for (j in 1:length(behave_data)){"
"0",""
"0","      pair_vec <- c(behave_data[[i]], behave_data[[j]])"
"0","      output_conv <- mean(pair_vec)"
"0","      divergence_df[i, j] <- (sample_max - output_conv)"
"0",""
"0","    }}"
"0",""
"0","  return(divergence_df)"
"0","}"
"0",""
"0","make_similarity_matrices <- function(behave_vec,"
"0","                                     index,"
"0","                                     center_value_list,"
"0","                                     resultpath,"
"0","                                     save_out){"
"0",""
"0","  dataframes2loopthrough <- list()"
"0",""
"0","  behave_nn <- nearest_neighbours(behave_vec) # absolute difference"
"0","  nn_name <- ""behave_nn"""
"0","  behave_conv <- convergence(behave_vec) # minimum pair"
"0","  conv_name <- ""behave_conv"""
"0","  behave_div <- divergence(behave_vec) # max(sample) - minimum pair"
"0","  div_name <- ""behave_div"""
"0",""
"0","  df_names_finn <- c(nn_name, conv_name, div_name)"
"0",""
"0","  df_names_behave <- c()"
"0","  df_names_punctuated <- c()"
"0","  "
"0","  for (i in 1:length(center_value_list)){"
"0","    behave_bow <- bow_tie(behave_vec, center_value_list[i]) # see function"
"0","    behave_punct <- punctuated(behave_vec, center_value_list[i]) # see function"
"0",""
"0","    df_name <- paste0('bow_tie_', center_value_list[i])"
"0","    df_names_behave[i] <- df_name"
"0","    "
"0","    df_name_punct <- paste0('punctuated_', center_value_list[i])"
"0","    df_names_punctuated[i] <- df_name_punct"
"0",""
"0","    assign(df_name, behave_bow)"
"0","    assign(df_name_punct, behave_punct)"
"0","  }"
"0",""
"0","  df_names <- c(df_names_finn, df_names_behave, df_names_punctuated)"
"0",""
"0","  dataframes2loopthrough <- do.call(""list"", mget(df_names))"
"0",""
"0","  for (df in 1:length(dataframes2loopthrough)){"
"0",""
"0","    df2use <- dataframes2loopthrough[[df]]"
"0",""
"0","    dfname <- names(dataframes2loopthrough)"
"0",""
"0","    final_df <- scale_matrix(df2use)"
"0",""
"0","    # replace diagonal values with 1"
"0","    diag(final_df) <- round(1, digits = 0)"
"0","    rownames(final_df) <- index"
"0",""
"0","    assign(dfname[df], final_df)"
"0",""
"0","    saveoutfilepath <- file.path(resultpath,"
"0","                                 paste0(dfname[df], "".csv""))"
"0",""
"0","    if(save_out == TRUE){"
"0","      write.csv(final_df, saveoutfilepath, row.names=FALSE)}"
"0",""
"0","  }"
"0",""
"0","  final_dataframes2loopthrough <- do.call(""list"", mget(df_names))"
"0","  "
"0","  return(final_dataframes2loopthrough)"
"0",""
"0","} # end function run behave model similarity"
"0",""
"0",""
"0","# compute similarity on single value output"
"0",""
"0","compute_single_variable_similarity <- function(single_v_data, "
"0","                                               subids,"
"0","                                               name2use,"
"0","                                               resultpath,"
"0","                                               save_out){"
"0","  "
"0","  matrix_similarity = data.frame()"
"0","  "
"0","  for (i in 1:length(single_v_data)){"
"0","    for (j in 1:length(single_v_data)){"
"0","      "
"0","      data_i = single_v_data[[i]]"
"0","      data_j = single_v_data[[j]]"
"0","      "
"0","      abs_diff = abs(data_i - data_j)"
"0","      "
"0","      matrix_similarity[i, j] = abs_diff"
"0","      "
"0","    }}"
"0","      "
"0","  matrix_scaled = 1 - scale_matrix(matrix_similarity)"
"0","  "
"0","  rownames(matrix_scaled) = subids"
"0","  colnames(matrix_scaled) = subids"
"0","  "
"0","  saveoutfilename <- paste0(name2use, "".csv"")"
"0","  saveoutfilepath <- file.path(resultpath, "
"0","                                saveoutfilename)"
"0","  "
"0","  if (save_out == TRUE){"
"0","    write.csv(matrix_scaled, saveoutfilepath, row.names=FALSE)}"
"0","  "
"0","  return(as.matrix(matrix_scaled))"
"0","}"
"0",""
"0","mantel_results_models <- function(x, y, nperm, n_models){"
"0","  "
"0","  # function takes two separate lists of dataframes as arguments"
"0","  # where x = list of data frames that model behavioral similarity (4 models)"
"0","  # and y = list of data frames that model dependent variable similarity"
"0","  # nperm is the n of permutations you want to run (i.e. 1000)"
"0","  # n_models is the number of behavioral models you are using FIX ME"
"0","  "
"0","  # using package vegan for the mantel() function, with spearman method*"
"0","  # *because distribution of similarity is not parametric "
"0","  # cit. https://jkzorz.github.io/2019/07/08/mantel-test.html"
"0","  "
"0","  # NB: switched to the vegan package, because the metan one was defaulting into spearman and there was no way to edit that (we need a non-parametric test)"
"0","  "
"0","  n_comparisons = length(y)"
"0",""
"0","  len_final_df = n_models*n_comparisons"
"0",""
"0","  model_res_r <- data.frame()"
"0","  model_res_p <- data.frame()"
"0","  rownames_df <- data.frame()"
"0",""
"0","  modelname = names(x)"
"0","  comparisonname = names(y)"
"0",""
"0","  for (i in 1:length(x)){"
"0","    for (j in 1:length(y)){"
"0",""
"0","        result_name <- paste0(modelname[i], comparisonname[j])"
"0",""
"0","        model2use = x[[i]]"
"0","        data2use = y[[j]]"
"0",""
"0","        model_out = mantel(model2use,"
"0","                           data2use,"
"0","                           method = ""spearman"","
"0","                           permutations = nperm,"
"0","                           na.rm = TRUE)"
"0",""
"0","        model_res_r <- rbind(model_res_r, "
"0","                             model_out$statistic) # r-value"
"0","        model_res_p <- rbind(model_res_p, "
"0","                             model_out$signif) # p-value"
"0",""
"0","        rownames_df <- rbind(rownames_df, result_name)"
"0","    }}"
"0",""
"0","  colnames(model_res_r) <- ""r"""
"0","  colnames(model_res_p) <- ""p_value"""
"0",""
"0","  model_res <- cbind(model_res_p, model_res_r)"
"0","  rownames(model_res) <- rownames_df[[1]]"
"0",""
"0","  model_res$p_value_adjusted <- p.adjust(model_res$p_value,"
"0","                                         method = ""fdr"")"
"0",""
"0","  return(model_res)"
"0",""
"0","} # end function mantel_results_models"
"0",""
"0",""
"0","compare_correlations <- function(r1_value,"
"0","                                 r2_value,"
"0","                                 alpha_level,"
"0","                                 n_1,"
"0","                                 n_2){"
"0","  "
"0","  # NB: applies to BOTH Pearson or Spearman's"
"0","  "
"0","  # REFs"
"0","  # https://blogs.sas.com/content/iml/2017/09/20/fishers-transformation-correlation.html"
"0","  # https://www.medcalc.org/manual/comparison-of-correlation-coefficients.php"
"0","  # Fisher (1925): http://krishikosh.egranth.ac.in/bitstream/1/2048218/1/0039_2689A.pdf"
"0","  # p_value from z score: https://www.r-bloggers.com/2022/05/calculate-the-p-value-from-z-score-in-r/"
"0","  "
"0","  # as a test case I used the exact values in the Medcalc link"
"0","  # and I got the same results "
"0","  "
"0","  result_names <- c(""r_values"","
"0","                    ""z_scores"","
"0","                    ""standard_error"","
"0","                    ""Fisher's z"","
"0","                    ""p_value"","
"0","                    ""significance"")"
"0","  result <- vector(""list"", length(result_names))"
"0","  names(result) <- result_names"
"0","  "
"0","  # save the original r values"
"0","  result[[""r_values""]] <- c(""r1"" = r1_value, ""r2"" = r2_value)"
"0","  "
"0","  # calculate z scores for the two pearson r coefficients"
"0","  z1_value <- (1/2)*log((1+r1_value)/(1-r1_value)) "
"0","  z2_value <- (1/2)*log((1+r2_value)/(1-r2_value)) "
"0","  result[[""z_scores""]] <- c(""z1"" = z1_value, ""z2"" = z2_value)"
"0","  "
"0","  # calculate the standard error based on sample size"
"0","  se_value1 <- (1/(n_1 - 3))"
"0","  se_value2 <- (1/(n_2 - 3))"
"0","  "
"0","  standard_error <- sqrt(se_value1 + se_value2)"
"0","  result[[""standard_error""]] <- standard_error"
"0","  "
"0","  # compute Fisher's z"
"0","  # NB: we need to take the absolute value because this "
"0","  # eliminates the effect of which correlation is "
"0","  # first and which is second"
"0","  "
"0","  z <- abs((z1_value - z2_value)/standard_error)"
"0","  result[[""Fisher's z""]] <- z"
"0","  "
"0","  # test significance of Fisher's z (rounded to 4 decimal places)"
"0","  # need to see the lower.tail to FALSE as we are only "
"0","  # evaluating positive z scores "
"0","  p_value <- pnorm(z, lower.tail = FALSE)"
"0","  p_value_formatted <- format(round(p_value, 4), nsmall = 4)"
"0","  "
"0","  significant <- ifelse(p_value > alpha_level, ""No"", ""Yes"")"
"0","  "
"0","  result[[""p_value""]] <- p_value_formatted "
"0","  result[[""significance""]] <- significant"
"0","  "
"0","  return(result)"
"0","}"
"0",""
